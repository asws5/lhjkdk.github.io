WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.865
Let's take a closer look at the AWS performance

00:00:02.865 --> 00:00:07.335
optimized instances and how they're used in workloads in the real world.

00:00:07.335 --> 00:00:10.995
When you need increased performance from your EC2 compute,

00:00:10.995 --> 00:00:15.300
it's imperative you understand how AWS optimized instances can

00:00:15.300 --> 00:00:20.025
provide you with higher throughput on your specialized intensive workloads.

00:00:20.025 --> 00:00:24.585
F1, P2, P3, G3,

00:00:24.585 --> 00:00:29.615
and G4 instances provide extremely accelerated computing resources,

00:00:29.615 --> 00:00:32.675
including instance, network, and GPU

00:00:32.675 --> 00:00:37.015
for super computing and applications like scientific image modeling.

00:00:37.015 --> 00:00:42.495
C4 and C5 instances are compute optimized instances,

00:00:42.495 --> 00:00:46.310
best used for compute bound applications that benefit from

00:00:46.310 --> 00:00:51.310
high performance processors like high performance computing and scientific modeling.

00:00:51.310 --> 00:00:55.610
T2 and T3 are burstable instances that are

00:00:55.610 --> 00:01:00.005
unique in their ability to perform beyond their baseline CPU resources.

00:01:00.005 --> 00:01:03.560
This flexibility and performance is achieved through tracking

00:01:03.560 --> 00:01:08.960
CPU credits that accumulate over time when the instance is running below capacity.

00:01:08.960 --> 00:01:10.730
When credits run out,

00:01:10.730 --> 00:01:16.750
the instances performance returns to its baseline and accumulation cycle continues.

00:01:16.750 --> 00:01:21.110
R4 and R5 are memory optimized instances,

00:01:21.110 --> 00:01:24.725
best for applications that process a lot of data in memory,

00:01:24.725 --> 00:01:27.200
like high performance databases.

00:01:27.200 --> 00:01:31.325
D2 instances are storage optimized instances.

00:01:31.325 --> 00:01:35.989
This new generation comes with massive scale ephemeral storage.

00:01:35.989 --> 00:01:38.570
It terminates when instance terminates,

00:01:38.570 --> 00:01:42.100
but is just still be a part of the cost conversation.

00:01:42.100 --> 00:01:45.770
Once your machine learning model is trained to meet your requirements,

00:01:45.770 --> 00:01:50.905
you can deploy your model on Inf1 instance by using AWS neuron.

00:01:50.905 --> 00:01:54.460
Inf1 instances are optimized for machine learning

00:01:54.460 --> 00:01:58.625
inference applications with AWS customized chips,

00:01:58.625 --> 00:02:01.750
scalable processors, and fast networking.

00:02:01.750 --> 00:02:05.030
An AWS neuron is a software developer kit for

00:02:05.030 --> 00:02:09.215
machine learning using the AWS customer Inferentia chips.

00:02:09.215 --> 00:02:11.825
That's a bit out of scope for this lesson,

00:02:11.825 --> 00:02:16.300
but it's good information to know about optimized EC2 instances.

00:02:16.300 --> 00:02:20.405
While instance types or families don't change much,

00:02:20.405 --> 00:02:23.900
their sizes and generations are updated quite frequently.

00:02:23.900 --> 00:02:27.185
So someone on the cloud team needs to stay on top of

00:02:27.185 --> 00:02:30.815
EC2 instance announcements on the AWS blog.

00:02:30.815 --> 00:02:35.585
These updates usually result in improved performance at a lower cost.

00:02:35.585 --> 00:02:40.060
So it's also a factor and how you decide on your reserved instance mix.

00:02:40.060 --> 00:02:43.430
You might not want to make a three-year reserved commitment to

00:02:43.430 --> 00:02:46.850
an instance type and reserve for one year instead,

00:02:46.850 --> 00:02:50.030
if you work at the type of company that wouldn't hesitate to move to

00:02:50.030 --> 00:02:54.660
a new generation to save money or improved performance.

