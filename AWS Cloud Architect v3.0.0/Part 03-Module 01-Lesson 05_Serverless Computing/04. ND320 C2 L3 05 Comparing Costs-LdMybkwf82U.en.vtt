WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.800
The attraction of faster, highly available,

00:00:03.800 --> 00:00:06.300
and scalable deployments, has attracted

00:00:06.300 --> 00:00:09.990
innovative deployment teams to the concept of going serverless.

00:00:09.990 --> 00:00:13.860
Fortunately, it frequently lives up to its promise of being faster and

00:00:13.860 --> 00:00:18.780
cheaper when the circumstances and configuration meet the requirements.

00:00:18.780 --> 00:00:23.310
While performance is a key driver for exploring serverless technology,

00:00:23.310 --> 00:00:26.460
there's also a cost incentive for applications that meet

00:00:26.460 --> 00:00:29.970
the criteria for optimal serverless functionality.

00:00:29.970 --> 00:00:35.040
Understand that not every application is going to be a good fit for AWS Lambda,

00:00:35.040 --> 00:00:36.900
but there will be plenty that are.

00:00:36.900 --> 00:00:42.700
Let's take a moment to compare compute costs between EC2 and Lambda in context.

00:00:42.700 --> 00:00:46.985
First, let's look at Lambda pricing as of March of 2020.

00:00:46.985 --> 00:00:52.895
Requests are build based on the number of requests and function invocations.

00:00:52.895 --> 00:00:59.320
In US East 1, that's $0.20 per one million requests and invocations.

00:00:59.320 --> 00:01:03.535
The price for duration depends on memory and time.

00:01:03.535 --> 00:01:08.300
You can allocate any amount of memory to your function between a minimum of

00:01:08.300 --> 00:01:14.740
128 megabytes and 3,000 megabytes and 64 megabytes increments.

00:01:14.740 --> 00:01:18.380
So let's say you have a website running on one

00:01:18.380 --> 00:01:23.235
t2.micro EC2 instance that you've reserved for a year.

00:01:23.235 --> 00:01:25.555
It has one CPU,

00:01:25.555 --> 00:01:27.665
and one gig of RAM.

00:01:27.665 --> 00:01:31.580
We can estimate that a site like this could pretty easily

00:01:31.580 --> 00:01:35.030
handle about 300 requests a day without issue.

00:01:35.030 --> 00:01:39.760
So we can estimate the monthly requests at about 9,000.

00:01:39.760 --> 00:01:45.425
The cost of running this instance is about $8.35 a month.

00:01:45.425 --> 00:01:48.620
Note that the number of users doesn't matter.

00:01:48.620 --> 00:01:52.235
Whether our site serves one visitor or 9,000,

00:01:52.235 --> 00:01:57.455
we're going to pay AWS $8.35 for the instance.

00:01:57.455 --> 00:02:04.235
We can imagine similar functionality using Lambda and the same metrics as follows.

00:02:04.235 --> 00:02:07.795
Nine thousand Lambda invocations,

00:02:07.795 --> 00:02:13.565
and we can estimate that each request uses the minimum a 128 megabytes of RAM,

00:02:13.565 --> 00:02:17.765
and that's just to be fair to our competitor, the EC2 instance,

00:02:17.765 --> 00:02:22.940
which only has one gig of RAM to handle everything, including requests.

00:02:22.940 --> 00:02:28.190
Each function has an average duration of 200 milliseconds.

00:02:28.190 --> 00:02:34.045
The grand total for AWS Lambda is a fraction of a cent.

00:02:34.045 --> 00:02:37.805
Lambda is free for a year using the free tier,

00:02:37.805 --> 00:02:41.195
and $0.20 for a million invocations thereafter.

00:02:41.195 --> 00:02:44.395
So we've barely scratched the surface there.

00:02:44.395 --> 00:02:51.365
I used the dashbird.io Lambda calculator to arrive at my final Lambda cost.

00:02:51.365 --> 00:02:57.110
It's a fast and fun calculator that runs in the browser and returns quick estimates.

00:02:57.110 --> 00:02:59.630
Check it out for yourself when you get a chance,

00:02:59.630 --> 00:03:02.165
and run some Lambda models of your own.

00:03:02.165 --> 00:03:08.945
Obviously, this is an example of how Lambda competes on a small scale with EC2.

00:03:08.945 --> 00:03:11.885
There are some cases where EC2 would be the champ,

00:03:11.885 --> 00:03:14.210
especially with long-running functions,

00:03:14.210 --> 00:03:18.110
because you pay for the duration of the CPU and the RAM usage.

00:03:18.110 --> 00:03:23.210
Thousands or millions of long-running serverless functions constantly running in

00:03:23.210 --> 00:03:28.135
parallel are definitely best executed on an EC2 instance,

00:03:28.135 --> 00:03:30.990
where pricing is stable and predictable,

00:03:30.990 --> 00:03:35.660
and long running functions can run without risking a cost surprise.

00:03:35.660 --> 00:03:39.245
Lambda functions are ephemeral and stateless,

00:03:39.245 --> 00:03:41.750
and they are run in short-lived containers

00:03:41.750 --> 00:03:44.495
that are destroyed after a period of inactivity.

00:03:44.495 --> 00:03:46.279
So when you call a function,

00:03:46.279 --> 00:03:51.430
chances are it is cold or not ready and will need some time to start up.

00:03:51.430 --> 00:03:55.250
AWS provides a keep warm service

00:03:55.250 --> 00:03:59.150
that maintains selected functions in an always ready state,

00:03:59.150 --> 00:04:03.390
preventing the cold-start delay for essential functions.

00:04:03.550 --> 00:04:08.915
Another way you save money with Lambda is on operations personnel.

00:04:08.915 --> 00:04:14.165
Developers partner with AWS as the apps in their DevOps team,

00:04:14.165 --> 00:04:15.740
and there's very little need for

00:04:15.740 --> 00:04:20.280
infrastructure support when running serverless applications.

